# Token Visualizer Docker

This directory contains the Docker configuration for the Token Visualizer application.

## Architecture

The Token Visualizer is a **Reflex application** with the following architecture:

- **Frontend Container** (`Dockerfile.frontend`): Static React frontend (generated by Reflex)
- **Backend Container** (`Dockerfile.backend`): Python Reflex backend that handles business logic and API calls

**Important**: The frontend communicates with the backend via WebSocket, and the **backend makes HTTP calls to the LLM service**.

## Environment Variables

### Frontend Container
The frontend container supports runtime configuration for connecting to the Reflex backend:

- `BACKEND_URL`: URL of the Reflex backend service (default: `http://localhost:8000`)
- `API_URL`: Override for API calls (default: same as `BACKEND_URL`)

### Backend Container
The backend container needs configuration to connect to the LLM service:

- `LLM_SERVICE_URL`: URL of the LLM service (default: `http://localhost:8001`)
- `LOCAL_MODEL_NAME`: Model name to use (default: `google/gemma-2-2b`)
- `HUGGINGFACE_TOKEN`: Hugging Face token for model access
- `DEVICE`: Device to use (default: `auto`)
- `USE_QUANTIZATION`: Enable quantization (default: `true`)
- `DEBUG`: Enable debug mode (default: `false`)

## Usage Examples

### Azure Container Apps

```bash
# Deploy backend (connects to LLM service)
az containerapp create \
  --name token-visualizer-backend \
  --image ghcr.io/tkubica12/d-ai-token-visualizer/token_visualizer_backend:latest \
  --env-vars LLM_SERVICE_URL=https://llm-service.internal.azurecontainerapps.io \
  --ingress internal --target-port 8000

# Deploy frontend (connects to backend)
az containerapp create \
  --name token-visualizer-frontend \
  --image ghcr.io/tkubica12/d-ai-token-visualizer/token_visualizer_frontend:latest \
  --env-vars BACKEND_URL=https://token-visualizer-backend.internal.azurecontainerapps.io \
  --ingress external --target-port 80
```

### Docker Compose

```yaml
version: '3.8'
services:
  # LLM Service (separate service)
  llm-service:
    image: ghcr.io/tkubica12/d-ai-token-visualizer/llm_service:cpu
    ports:
      - "8001:8001"
    environment:
      - HUGGINGFACE_TOKEN=your_token_here
  
  # Reflex Backend
  backend:
    image: ghcr.io/tkubica12/d-ai-token-visualizer/token_visualizer_backend:latest
    ports:
      - "8000:8000"
    environment:
      - LLM_SERVICE_URL=http://llm-service:8001
      - HUGGINGFACE_TOKEN=your_token_here
    depends_on:
      - llm-service
  
  # Reflex Frontend
  frontend:
    image: ghcr.io/tkubica12/d-ai-token-visualizer/token_visualizer_frontend:latest
    ports:
      - "3000:80"
    environment:
      - BACKEND_URL=http://backend:8000
    depends_on:
      - backend
```

## Communication Flow

```
User Browser → Frontend (nginx) → Backend (Reflex Python) → LLM Service (HTTP API)
              WebSocket/HTTP      HTTP calls
```

1. **User** interacts with React frontend
2. **Frontend** communicates with Reflex backend via WebSocket
3. **Backend** makes HTTP calls to LLM service
4. **Backend** returns results to frontend via WebSocket

## Building the Images

```bash
# Build frontend (static React app)
docker build -f Dockerfile.frontend -t token-visualizer-frontend .

# Build backend (Reflex Python app)
docker build -f Dockerfile.backend -t token-visualizer-backend .
```

## Running Locally

```bash
# Start LLM service first
docker run -p 8001:8001 \
  -e HUGGINGFACE_TOKEN=your_token_here \
  ghcr.io/tkubica12/d-ai-token-visualizer/llm_service:cpu

# Start backend (connects to LLM service)
docker run -p 8000:8000 \
  -e LLM_SERVICE_URL=http://host.docker.internal:8001 \
  -e HUGGINGFACE_TOKEN=your_token_here \
  token-visualizer-backend

# Start frontend (connects to backend)
docker run -p 3000:80 \
  -e BACKEND_URL=http://host.docker.internal:8000 \
  token-visualizer-frontend
```

## GitHub Actions

Images are automatically built and pushed to GitHub Container Registry:
- `ghcr.io/tkubica12/d-ai-token-visualizer/token_visualizer_frontend:latest`
- `ghcr.io/tkubica12/d-ai-token-visualizer/token_visualizer_backend:latest`
